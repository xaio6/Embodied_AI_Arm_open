"""
é˜¿é‡Œäº‘ASRæä¾›å•†
ä½¿ç”¨DashScope SDKå®ç°è¯­éŸ³è¯†åˆ«åŠŸèƒ½
"""

import os
import time
import asyncio
import threading
import concurrent.futures
from typing import Dict, Any, Generator, AsyncGenerator, Optional
import pyaudio
import wave
import io
from ..base import BaseASRProvider

try:
    import dashscope
    from dashscope.audio.asr import Recognition, RecognitionCallback
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False


class AlibabaASRProvider(BaseASRProvider):
    """é˜¿é‡Œäº‘ASRæä¾›å•†"""
    
    def __init__(self, api_key: str, **kwargs):
        super().__init__(api_key, **kwargs)
        
        if not DASHSCOPE_AVAILABLE:
            raise ImportError("è¯·å®‰è£… dashscope: pip install dashscope")
        
        # è®¾ç½®API Key
        dashscope.api_key = api_key
        
        # éŸ³é¢‘å‚æ•°
        self.sample_rate = kwargs.get('sample_rate', 16000)
        self.channels = kwargs.get('channels', 1)
        self.chunk_size = kwargs.get('chunk_size', 3200)
        
        # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
        self.supported_formats = ['wav', 'mp3', 'pcm', 'aac', 'amr', 'ogg']
        
        # é»˜è®¤æ¨¡å‹
        self.default_model = kwargs.get('model', 'paraformer-realtime-v2')
    
    def _validate_audio_file(self, audio_file: str) -> bool:
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶"""
        if not os.path.exists(audio_file):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        
        file_ext = os.path.splitext(audio_file)[1][1:].lower()
        if file_ext not in self.supported_formats:
            raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {file_ext}ï¼Œæ”¯æŒçš„æ ¼å¼: {self.supported_formats}")
        
        return True
    
    def recognize_file(self, audio_file: str, **kwargs) -> Dict[str, Any]:
        """è¯†åˆ«éŸ³é¢‘æ–‡ä»¶"""
        self._validate_audio_file(audio_file)
        
        try:
            # ä½¿ç”¨åŒæ­¥è°ƒç”¨æ–¹å¼
            model = kwargs.get('model', self.default_model)
            
            # åˆ›å»ºè¯†åˆ«å™¨
            recognizer = Recognition(
                model=model,
                format='wav',
                sample_rate=self.sample_rate,
                callback=None  # åŒæ­¥è°ƒç”¨ä¸éœ€è¦å›è°ƒ
            )
            
            # ç›´æ¥è°ƒç”¨æ–‡ä»¶è¯†åˆ«
            result = recognizer.call(audio_file)
            
            # æ£€æŸ¥çŠ¶æ€ç 
            if hasattr(result, 'status_code') and result.status_code.value == 200:
                # ä½¿ç”¨å®˜æ–¹æ¨èçš„get_sentence()æ–¹æ³•è·å–ç»“æœ
                sentences = result.get_sentence()
                
                if sentences:
                    # æå–æ‰€æœ‰å¥å­çš„æ–‡æœ¬
                    full_text = ""
                    total_confidence = 0.0
                    sentence_count = 0
                    
                    # sentenceså¯èƒ½æ˜¯å•ä¸ªå¥å­dictæˆ–å¥å­åˆ—è¡¨
                    if isinstance(sentences, dict):
                        sentences = [sentences]
                    elif isinstance(sentences, list):
                        pass
                    else:
                        # å¦‚æœä¸æ˜¯é¢„æœŸæ ¼å¼ï¼Œå°è¯•ä»outputä¸­è·å–
                        if hasattr(result, 'output') and result.output:
                            if 'sentence' in result.output:
                                sentences = result.output['sentence']
                            else:
                                sentences = []
                    
                    for sentence in sentences:
                        if isinstance(sentence, dict) and 'text' in sentence:
                            full_text += sentence['text']
                            sentence_count += 1
                            # å¦‚æœæœ‰ç½®ä¿¡åº¦ä¿¡æ¯ï¼Œç´¯åŠ è®¡ç®—å¹³å‡å€¼
                            if 'confidence' in sentence:
                                total_confidence += sentence.get('confidence', 0.0)
                    
                    # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
                    avg_confidence = total_confidence / sentence_count if sentence_count > 0 else 0.0
                    
                    return {
                        'success': True,
                        'text': full_text,
                        'confidence': avg_confidence,
                        'audio_duration': 0,
                        'processing_time': 0,
                        'sentences': sentences,  # ä¿ç•™åŸå§‹å¥å­ä¿¡æ¯
                        'request_id': getattr(result, 'request_id', '')
                    }
                else:
                    return {
                        'success': False,
                        'error': "è¯†åˆ«ç»“æœä¸ºç©º",
                        'text': '',
                        'confidence': 0.0
                    }
            else:
                # è¯†åˆ«å¤±è´¥
                error_msg = getattr(result, 'message', 'æœªçŸ¥é”™è¯¯')
                return {
                    'success': False,
                    'error': f"è¯†åˆ«å¤±è´¥: {error_msg}",
                    'text': '',
                    'confidence': 0.0
                }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"æ–‡ä»¶è¯†åˆ«å¤±è´¥: {str(e)}",
                'text': '',
                'confidence': 0.0
            }
    
    async def recognize_file_async(self, audio_file: str, **kwargs) -> Dict[str, Any]:
        """å¼‚æ­¥è¯†åˆ«éŸ³é¢‘æ–‡ä»¶"""
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æ–¹æ³•
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            result = await loop.run_in_executor(executor, self.recognize_file, audio_file, **kwargs)
            return result
    
    def recognize_stream(self, audio_stream, **kwargs) -> Generator[Dict[str, Any], None, None]:
        """å®æ—¶è¯­éŸ³è¯†åˆ«"""
        try:
            model = kwargs.get('model', self.default_model)
            
            # åˆ›å»ºå›è°ƒç±»æ¥å¤„ç†æµå¼ç»“æœ
            class StreamCallback(RecognitionCallback):
                def __init__(self):
                    self.results = []
                    self.error_message = None
                
                def on_open(self):
                    pass
                
                def on_close(self):
                    pass
                
                def on_event(self, result):
                    if result and hasattr(result, 'status_code') and result.status_code.value == 200:
                        # ä½¿ç”¨get_sentence()æ–¹æ³•è·å–ç»“æœ
                        sentences = result.get_sentence()
                        
                        if sentences:
                            # sentenceså¯èƒ½æ˜¯å•ä¸ªå¥å­dictæˆ–å¥å­åˆ—è¡¨
                            if isinstance(sentences, dict):
                                sentences = [sentences]
                            
                            for sentence in sentences:
                                if isinstance(sentence, dict) and 'text' in sentence:
                                    self.results.append({
                                        'success': True,
                                        'text': sentence['text'],
                                        'confidence': sentence.get('confidence', 0.0),
                                        'is_final': sentence.get('sentence_end', False),
                                        'begin_time': sentence.get('begin_time', 0),
                                        'end_time': sentence.get('end_time', 0),
                                        'sentence_id': sentence.get('sentence_id', 0)
                                    })
                
                def on_error(self, result):
                    error_msg = getattr(result, 'message', 'æœªçŸ¥é”™è¯¯')
                    self.error_message = error_msg
                    self.results.append({
                        'success': False,
                        'error': self.error_message,
                        'text': '',
                        'confidence': 0.0,
                        'is_final': False
                    })
                
                def on_complete(self):
                    pass
            
            callback = StreamCallback()
            
            # åˆ›å»ºè¯†åˆ«å™¨
            recognizer = Recognition(
                model=model,
                format='pcm',
                sample_rate=self.sample_rate,
                callback=callback
            )
            
            # å¼€å§‹è¯†åˆ«
            recognizer.start()
            
            try:
                # å¤„ç†éŸ³é¢‘æµ
                for audio_chunk in audio_stream:
                    recognizer.send_audio_frame(audio_chunk)
                    
                    # è¿”å›ç´¯ç§¯çš„ç»“æœ
                    while callback.results:
                        yield callback.results.pop(0)
                    
                    time.sleep(0.01)  # çŸ­æš‚å»¶è¿Ÿ
                
                # åœæ­¢è¯†åˆ«
                recognizer.stop()
                
                # è¿”å›å‰©ä½™ç»“æœ
                while callback.results:
                    yield callback.results.pop(0)
                    
            except Exception as e:
                yield {
                    'success': False,
                    'error': f"æµå¼è¯†åˆ«é”™è¯¯: {str(e)}",
                    'text': '',
                    'confidence': 0.0,
                    'is_final': False
                }
            
        except Exception as e:
            yield {
                'success': False,
                'error': f"å®æ—¶è¯†åˆ«å¤±è´¥: {str(e)}",
                'text': '',
                'confidence': 0.0,
                'is_final': False
            }
    
    async def recognize_stream_async(self, audio_stream, **kwargs) -> AsyncGenerator[Dict[str, Any], None]:
        """å¼‚æ­¥å®æ—¶è¯­éŸ³è¯†åˆ«"""
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ç”Ÿæˆå™¨
        loop = asyncio.get_event_loop()
        
        def sync_generator():
            return list(self.recognize_stream(audio_stream, **kwargs))
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results = await loop.run_in_executor(None, sync_generator)
            
            for result in results:
                yield result
    
    def recognize_microphone(self, duration: int = 5, **kwargs) -> Dict[str, Any]:
        """è¯†åˆ«éº¦å…‹é£éŸ³é¢‘"""
        try:
            # åˆå§‹åŒ–PyAudio
            audio = pyaudio.PyAudio()
            
            # éŸ³é¢‘å‚æ•°
            sample_rate = kwargs.get('sample_rate', self.sample_rate)
            channels = kwargs.get('channels', self.channels)
            chunk_size = kwargs.get('chunk_size', self.chunk_size)
            
            print(f"å¼€å§‹å½•éŸ³ï¼Œæ—¶é•¿: {duration}ç§’...")
            
            # å¼€å§‹å½•éŸ³
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=channels,
                rate=sample_rate,
                input=True,
                frames_per_buffer=chunk_size
            )
            
            # åˆ›å»ºå›è°ƒç±»æ¥æ”¶é›†è¯†åˆ«ç»“æœ
            class MicCallback(RecognitionCallback):
                def __init__(self):
                    self.final_text = ""
                    self.confidence = 0.0
                    self.error_message = None
                    self.sentence_count = 0
                
                def on_open(self):
                    pass
                
                def on_close(self):
                    pass
                
                def on_event(self, result):
                    if result and hasattr(result, 'status_code') and result.status_code.value == 200:
                        sentences = result.get_sentence()
                        
                        if sentences:
                            if isinstance(sentences, dict):
                                sentences = [sentences]
                            
                            for sentence in sentences:
                                if isinstance(sentence, dict) and 'text' in sentence:
                                    # åªå¤„ç†å®Œæ•´çš„å¥å­
                                    if sentence.get('sentence_end', False):
                                        self.final_text += sentence['text']
                                        self.sentence_count += 1
                                        if 'confidence' in sentence:
                                            self.confidence += sentence.get('confidence', 0.0)
                
                def on_error(self, result):
                    self.error_message = getattr(result, 'message', 'æœªçŸ¥é”™è¯¯')
                
                def on_complete(self):
                    pass
            
            callback = MicCallback()
            
            # åˆ›å»ºè¯†åˆ«å™¨
            recognizer = Recognition(
                model=kwargs.get('model', self.default_model),
                format='pcm',
                sample_rate=sample_rate,
                callback=callback
            )
            
            # å¼€å§‹è¯†åˆ«
            recognizer.start()
            
            # å½•éŸ³å¹¶å®æ—¶å‘é€æ•°æ®
            frames_to_record = int(sample_rate / chunk_size * duration)
            for _ in range(frames_to_record):
                data = stream.read(chunk_size)
                recognizer.send_audio_frame(data)
                time.sleep(0.01)  # æ§åˆ¶å‘é€é¢‘ç‡
            
            print("å½•éŸ³ç»“æŸï¼Œç­‰å¾…è¯†åˆ«å®Œæˆ...")
            
            # åœæ­¢å½•éŸ³
            stream.stop_stream()
            stream.close()
            # å®‰å…¨åœ°å…³é—­PyAudioï¼Œé¿å…ç¨‹åºé€€å‡º
            audio = None
            
            # åœæ­¢è¯†åˆ«
            recognizer.stop()
            
            if callback.error_message:
                return {
                    'success': False,
                    'error': callback.error_message,
                    'text': '',
                    'confidence': 0.0
                }
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = callback.confidence / callback.sentence_count if callback.sentence_count > 0 else 0.0
            
            return {
                'success': True,
                'text': callback.final_text,
                'confidence': avg_confidence,
                'audio_duration': duration,
                'processing_time': 0
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"éº¦å…‹é£è¯†åˆ«å¤±è´¥: {str(e)}",
                'text': '',
                'confidence': 0.0
            }
    
    def keyword_spotting(self, keywords: list, **kwargs) -> Generator[Dict[str, Any], None, None]:
        """å…³é”®è¯è¯†åˆ«å”¤é†’ - åªæœ‰æ£€æµ‹åˆ°å…³é”®è¯æ—¶æ‰è¿”å›ç»“æœ"""
        try:
            # åˆå§‹åŒ–PyAudio
            audio = pyaudio.PyAudio()
            
            # éŸ³é¢‘å‚æ•°
            sample_rate = kwargs.get('sample_rate', self.sample_rate)
            channels = kwargs.get('channels', self.channels)
            chunk_size = kwargs.get('chunk_size', self.chunk_size)
            
            # å…³é”®è¯æ£€æµ‹å‚æ•°
            detection_threshold = kwargs.get('detection_threshold', 0.6)
            silence_timeout = kwargs.get('silence_timeout', 3.0)
            max_audio_length = kwargs.get('max_audio_length', 15)
            debug_mode = kwargs.get('debug_mode', False)  # é»˜è®¤å…³é—­è°ƒè¯•æ¨¡å¼
            
            # å°†å…³é”®è¯è½¬æ¢ä¸ºå°å†™ä»¥ä¾¿åŒ¹é…
            keywords_lower = [kw.lower().strip() for kw in keywords]
            
            print(f"ğŸ” å¼€å§‹å…³é”®è¯æ£€æµ‹ï¼Œç›®æ ‡å…³é”®è¯: {keywords}")
            print(f"ğŸ”‡ é™é»˜ç›‘å¬ä¸­...")
            
            # å¼€å§‹å½•éŸ³
            stream = audio.open(
                format=pyaudio.paInt16,
                channels=channels,
                rate=sample_rate,
                input=True,
                frames_per_buffer=chunk_size
            )
            
            # åˆ›å»ºå›è°ƒç±»æ¥å¤„ç†å…³é”®è¯æ£€æµ‹
            class KeywordDetectionCallback(RecognitionCallback):
                def __init__(self, target_keywords, threshold, debug=False):
                    self.target_keywords = target_keywords
                    self.threshold = threshold
                    self.debug = debug
                    self.detected_results = []
                    self.current_text = ""
                    self.current_confidence = 0.0
                    self.error_message = None
                
                def on_open(self):
                    if self.debug:
                        print("ğŸ”— ASRè¿æ¥å·²å»ºç«‹")
                
                def on_close(self):
                    if self.debug:
                        print("ğŸ”Œ ASRè¿æ¥å·²å…³é—­")
                
                def on_event(self, result):
                    if self.debug:
                        print(f"ğŸ“¥ æ”¶åˆ°ASRäº‹ä»¶: {result}")
                    
                    if result and hasattr(result, 'status_code') and result.status_code.value == 200:
                        sentences = result.get_sentence()
                        
                        if sentences:
                            if isinstance(sentences, dict):
                                sentences = [sentences]
                            
                            for sentence in sentences:
                                if isinstance(sentence, dict) and 'text' in sentence:
                                    text = sentence['text'].strip()
                                    confidence = sentence.get('confidence', 0.0)
                                    is_final = sentence.get('sentence_end', False)
                                    
                                    if self.debug:
                                        print(f"ğŸ“ è¯†åˆ«æ–‡æœ¬: '{text}' (ç½®ä¿¡åº¦: {confidence:.2f}, å®Œæ•´: {is_final})")
                                    
                                    # æ›´æ–°å½“å‰è¯†åˆ«æ–‡æœ¬
                                    self.current_text = text
                                    self.current_confidence = confidence
                                    
                                    # åªåœ¨å¥å­ç»“æŸæ—¶æ£€æŸ¥å…³é”®è¯ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„è¯†åˆ«ç»“æœ
                                    if is_final and text:
                                        text_lower = text.lower()
                                        
                                        # å»é™¤æ ‡ç‚¹ç¬¦å·è¿›è¡ŒåŒ¹é…
                                        import re
                                        text_clean = re.sub(r'[^\w\s]', '', text_lower)  # å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·
                                        
                                        if self.debug:
                                            print(f"ğŸ” æ£€æŸ¥å…³é”®è¯: '{text_clean}' (åŸæ–‡: '{text_lower}') vs {self.target_keywords}")
                                        
                                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•ç›®æ ‡å…³é”®è¯ï¼ˆä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼‰
                                        for keyword in self.target_keywords:
                                            # ä½¿ç”¨è¯è¾¹ç•Œæ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œç²¾ç¡®åŒ¹é…
                                            pattern = r'\b' + re.escape(keyword) + r'\b'
                                            if re.search(pattern, text_clean):
                                                if self.debug:
                                                    print(f"ğŸ¯ æ‰¾åˆ°åŒ¹é…å…³é”®è¯: '{keyword}' in '{text_clean}'")
                                                
                                                # æ‰¾åˆ°åŒ¹é…çš„å…³é”®è¯
                                                self.detected_results.append({
                                                    'success': True,
                                                    'keyword_detected': keyword,
                                                    'text': text,  # è¿”å›åŸå§‹æ–‡æœ¬ï¼ˆå¸¦æ ‡ç‚¹ï¼‰
                                                    'confidence': confidence if confidence > 0 else 0.9,
                                                    'timestamp': time.time(),
                                                    'sentence_id': sentence.get('sentence_id', 0),
                                                    'begin_time': sentence.get('begin_time', 0),
                                                    'end_time': sentence.get('end_time', 0),
                                                    'is_final': is_final
                                                })
                                                return  # æ‰¾åˆ°å…³é”®è¯åç«‹å³è¿”å›
                    else:
                        if self.debug:
                            print(f"âš ï¸ ASRäº‹ä»¶çŠ¶æ€å¼‚å¸¸: {result}")
                
                def on_error(self, result):
                    error_msg = getattr(result, 'message', 'æœªçŸ¥é”™è¯¯')
                    self.error_message = error_msg
                    if self.debug:
                        print(f"âŒ ASRé”™è¯¯: {error_msg}")
                
                def on_complete(self):
                    if self.debug:
                        print("âœ… ASRè¯†åˆ«å®Œæˆ")
            
            callback = KeywordDetectionCallback(keywords_lower, detection_threshold, debug_mode)
            
            # åˆ›å»ºè¯†åˆ«å™¨ - å¯ç”¨æ ‡ç‚¹ç¬¦å·é¢„æµ‹
            recognizer = Recognition(
                model=kwargs.get('model', self.default_model),
                format='pcm',
                sample_rate=sample_rate,
                callback=callback,
                # å¯ç”¨æ ‡ç‚¹ç¬¦å·é¢„æµ‹ï¼Œç„¶ååœ¨ä»£ç ä¸­å¤„ç†æ ‡ç‚¹ç¬¦å·åŒ¹é…
                punctuation_prediction_enabled=True
            )
            
            # å¼€å§‹è¯†åˆ«
            recognizer.start()
            
            try:
                audio_buffer = []
                frames_count = 0
                max_frames = int(sample_rate / chunk_size * max_audio_length)
                silence_frames = int(sample_rate / chunk_size * silence_timeout)
                consecutive_silence = 0
                last_activity_time = time.time()
                
                while True:
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    data = stream.read(chunk_size, exception_on_overflow=False)
                    audio_buffer.append(data)
                    frames_count += 1
                    
                    # å‘é€éŸ³é¢‘æ•°æ®åˆ°è¯†åˆ«å™¨
                    recognizer.send_audio_frame(data)
                    
                    # æ£€æµ‹éŸ³é¢‘èƒ½é‡ï¼ˆç®€å•çš„é™éŸ³æ£€æµ‹ï¼‰
                    import struct
                    audio_data = struct.unpack(f'{len(data)//2}h', data)
                    energy = sum(abs(sample) for sample in audio_data) / len(audio_data)
                    
                    if energy < 300:  # é™éŸ³é˜ˆå€¼
                        consecutive_silence += 1
                    else:
                        consecutive_silence = 0
                        last_activity_time = time.time()
                        if debug_mode and time.time() - last_activity_time > 2:
                            print(f"ğŸ”Š æ£€æµ‹åˆ°éŸ³é¢‘æ´»åŠ¨")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ£€æµ‹åˆ°çš„å…³é”®è¯
                    if callback.detected_results:
                        # æ‰¾åˆ°å…³é”®è¯ï¼Œè¿”å›ç»“æœ
                        result = callback.detected_results.pop(0)
                        print(f"ğŸ‰ æ£€æµ‹åˆ°å…³é”®è¯: {result['keyword_detected']}")
                        yield result
                        
                        # é‡ç½®çŠ¶æ€ï¼Œç»§ç»­ç›‘å¬ä¸‹ä¸€ä¸ªå…³é”®è¯
                        callback.detected_results.clear()
                        callback.current_text = ""
                        callback.current_confidence = 0.0
                        audio_buffer.clear()
                        frames_count = 0
                        consecutive_silence = 0
                        print("ğŸ”‡ ç»§ç»­é™é»˜ç›‘å¬...")
                        continue
                    
                    # æ£€æŸ¥é”™è¯¯
                    if callback.error_message:
                        yield {
                            'success': False,
                            'error': callback.error_message,
                            'keyword_detected': '',
                            'text': '',
                            'confidence': 0.0
                        }
                        callback.error_message = None
                    
                    # è¶…æ—¶å¤„ç†ï¼šå¦‚æœè¿ç»­é™éŸ³å¤ªä¹…æˆ–éŸ³é¢‘å¤ªé•¿ï¼Œé‡ç½®ç¼“å†²åŒº
                    if consecutive_silence >= silence_frames or frames_count >= max_frames:
                        if debug_mode:
                            if consecutive_silence >= silence_frames:
                                print(f"ğŸ”‡ é™éŸ³è¶…æ—¶ï¼Œé‡ç½®ç¼“å†²åŒº")
                            else:
                                print(f"â±ï¸ éŸ³é¢‘é•¿åº¦è¶…æ—¶ï¼Œé‡ç½®ç¼“å†²åŒº")
                        
                        # æ¸…ç©ºç¼“å†²åŒºï¼Œé‡æ–°å¼€å§‹
                        audio_buffer.clear()
                        frames_count = 0
                        consecutive_silence = 0
                        callback.current_text = ""
                        callback.current_confidence = 0.0
                    
                    time.sleep(0.01)  # æ§åˆ¶å¾ªç¯é¢‘ç‡
                    
            except KeyboardInterrupt:
                print("\nğŸ›‘ å…³é”®è¯æ£€æµ‹å·²åœæ­¢")
            finally:
                recognizer.stop()
                stream.stop_stream()
                stream.close()
                # å®‰å…¨åœ°å…³é—­PyAudioï¼Œé¿å…ç¨‹åºé€€å‡º
                audio = None
                
        except Exception as e:
            yield {
                'success': False,
                'error': f"å…³é”®è¯æ£€æµ‹å¤±è´¥: {str(e)}",
                'keyword_detected': '',
                'text': '',
                'confidence': 0.0
            } 