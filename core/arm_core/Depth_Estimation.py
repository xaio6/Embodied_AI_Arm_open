#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒç›®é±¼çœ¼ç›¸æœºæ·±åº¦ä¼°è®¡ç®—æ³•
æ”¯æŒé±¼çœ¼å’Œé’ˆå­”æ¨¡å‹çš„ç«‹ä½“è§†è§‰æ·±åº¦è®¡ç®—
é’ˆå¯¹105Â°å¹¿è§’é±¼çœ¼ç›¸æœºä¼˜åŒ–
"""

import cv2
import numpy as np
import json
import os
from typing import Tuple, Optional, Dict, Any

class StereoDepthEstimator:
    """åŒç›®æ·±åº¦ä¼°è®¡å™¨"""
    
    def __init__(self, config_path: str = "config/calibration_parameter.json"):
        """
        åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨
        
        Args:
            config_path: æ ‡å®šå‚æ•°é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.camera_model = 'pinhole'
        
        # ç›¸æœºå‚æ•°
        self.K1 = None  # å·¦ç›¸æœºå†…å‚
        self.D1 = None  # å·¦ç›¸æœºç•¸å˜
        self.K2 = None  # å³ç›¸æœºå†…å‚  
        self.D2 = None  # å³ç›¸æœºç•¸å˜
        self.R = None   # æ—‹è½¬çŸ©é˜µ
        self.T = None   # å¹³ç§»å‘é‡
        
        # ç«‹ä½“æ ¡æ­£å‚æ•°
        self.R1 = None  # å·¦ç›¸æœºæ ¡æ­£æ—‹è½¬çŸ©é˜µ
        self.R2 = None  # å³ç›¸æœºæ ¡æ­£æ—‹è½¬çŸ©é˜µ
        self.P1 = None  # å·¦ç›¸æœºæ ¡æ­£æŠ•å½±çŸ©é˜µ
        self.P2 = None  # å³ç›¸æœºæ ¡æ­£æŠ•å½±çŸ©é˜µ
        self.Q = None   # è§†å·®åˆ°æ·±åº¦æ˜ å°„çŸ©é˜µ
        
        # æ ¡æ­£æ˜ å°„
        self.map1_left = None
        self.map2_left = None
        self.map1_right = None
        self.map2_right = None
        
        # è§†å·®è®¡ç®—å™¨
        self.stereo_matcher = None
        
        # å›¾åƒå°ºå¯¸
        self.image_size = None
        
        # åŠ è½½æ ‡å®šå‚æ•°
        self.load_calibration_params()
        
    def load_calibration_params(self) -> bool:
        """åŠ è½½åŒç›®æ ‡å®šå‚æ•°"""
        try:
            if not os.path.exists(self.config_path):
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
                return False
                
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            two_config = config.get('two', {})
            if not two_config:
                print("âŒ æœªæ‰¾åˆ°åŒç›®ç›¸æœºæ ‡å®šå‚æ•°")
                return False
            
            # åŠ è½½ç›¸æœºå†…å‚
            self.K1 = np.array(two_config.get('left_camera_matrix', []), dtype=np.float64)
            self.K2 = np.array(two_config.get('right_camera_matrix', []), dtype=np.float64)
            
            # åŠ è½½ç•¸å˜ç³»æ•°ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰
            left_distortion = two_config.get('left_distortion', [])
            right_distortion = two_config.get('right_distortion', [])
            
            self.D1 = self._parse_distortion_coeffs(left_distortion)
            self.D2 = self._parse_distortion_coeffs(right_distortion)
            
            # åŠ è½½å¤–å‚
            self.R = np.array(two_config.get('R', []), dtype=np.float64)
            self.T = np.array(two_config.get('T', []), dtype=np.float64).reshape(3, 1)
            
            # è·å–ç›¸æœºæ¨¡å‹
            self.camera_model = two_config.get('model', 'pinhole')
            
            # è®¡ç®—åŸºçº¿è·ç¦»
            baseline = abs(self.T[0, 0]) / 1000.0  # è½¬æ¢ä¸ºç±³ï¼ˆé…ç½®ä¸­æ˜¯mmï¼‰
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½åŒç›®æ ‡å®šå‚æ•°å¤±è´¥: {e}")
            return False
    
    def _parse_distortion_coeffs(self, distortion_data) -> np.ndarray:
        """è§£æç•¸å˜ç³»æ•°ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰"""
        if not distortion_data:
            return np.zeros(4 if self.camera_model == 'fisheye' else 5, dtype=np.float64)
        
        if len(distortion_data) > 0:
            if isinstance(distortion_data[0], list):
                if len(distortion_data[0]) > 1:
                    # æ—§æ ¼å¼ï¼š[[-0.04169075, -0.10853007, ...]]
                    return np.array(distortion_data[0], dtype=np.float64)
                else:
                    # æ–°æ ¼å¼ï¼š[[0.281...], [0.074...], ...]
                    return np.array([row[0] for row in distortion_data if len(row) > 0], dtype=np.float64)
            else:
                return np.array(distortion_data, dtype=np.float64)
        
        return np.zeros(4 if self.camera_model == 'fisheye' else 5, dtype=np.float64)
    
    def setup_stereo_rectification(self, image_size: Tuple[int, int]) -> bool:
        """è®¾ç½®ç«‹ä½“æ ¡æ­£å‚æ•°"""
        try:
            if any(param is None for param in [self.K1, self.K2, self.D1, self.D2, self.R, self.T]):
                print("âŒ æ ‡å®šå‚æ•°ä¸å®Œæ•´ï¼Œæ— æ³•è¿›è¡Œç«‹ä½“æ ¡æ­£")
                return False
            
            self.image_size = image_size
            w, h = image_size
            
            # å°†Tè½¬æ¢ä¸ºæ­£ç¡®çš„å•ä½ï¼ˆç±³ï¼‰
            T_meters = self.T.copy()
            if abs(T_meters[0, 0]) > 10:  # å¦‚æœTçš„å€¼å¾ˆå¤§ï¼Œè¯´æ˜å•ä½æ˜¯mm
                T_meters = T_meters / 1000.0
            
            if self.camera_model == 'fisheye':
                # é±¼çœ¼ç«‹ä½“æ ¡æ­£ - ä¿®å¤å‚æ•°ä¼ é€’
                try:
                    # æ–¹æ³•1ï¼šä½¿ç”¨ç®€åŒ–çš„é±¼çœ¼æ ¡æ­£
                    balance = 0.0
                    fov_scale = 1.0
                    
                    # è®¡ç®—æ–°çš„ç›¸æœºçŸ©é˜µ
                    new_K1 = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(
                        self.K1, self.D1.reshape(4, 1), (w, h), np.eye(3), balance=balance
                    )
                    new_K2 = cv2.fisheye.estimateNewCameraMatrixForUndistortRectify(
                        self.K2, self.D2.reshape(4, 1), (w, h), np.eye(3), balance=balance
                    )
                    
                    # ä½¿ç”¨æ ‡å‡†çš„ç«‹ä½“æ ¡æ­£ï¼ˆä¸ä½¿ç”¨é±¼çœ¼ä¸“ç”¨å‡½æ•°ï¼‰
                    self.R1, self.R2, self.P1, self.P2, self.Q, _, _ = cv2.stereoRectify(
                        cameraMatrix1=new_K1, distCoeffs1=np.zeros(5),
                        cameraMatrix2=new_K2, distCoeffs2=np.zeros(5),
                        imageSize=(w, h),
                        R=self.R, T=T_meters,
                        flags=cv2.CALIB_ZERO_DISPARITY,
                        alpha=0.0
                    )
                    
                    # è®¡ç®—é±¼çœ¼æ ¡æ­£æ˜ å°„
                    self.map1_left, self.map2_left = cv2.fisheye.initUndistortRectifyMap(
                        self.K1, self.D1.reshape(4, 1), self.R1, self.P1, (w, h), cv2.CV_16SC2
                    )
                    self.map1_right, self.map2_right = cv2.fisheye.initUndistortRectifyMap(
                        self.K2, self.D2.reshape(4, 1), self.R2, self.P2, (w, h), cv2.CV_16SC2
                    )
                    
                    print("âœ… é±¼çœ¼ç«‹ä½“æ ¡æ­£è®¾ç½®å®Œæˆï¼ˆæ··åˆæ–¹æ³•ï¼‰")
                    
                except Exception as fisheye_error:
                    print(f"âš ï¸ é±¼çœ¼ä¸“ç”¨æ ¡æ­£å¤±è´¥ï¼Œå°è¯•æ ‡å‡†æ–¹æ³•: {fisheye_error}")
                    
                    # æ–¹æ³•2ï¼šå›é€€åˆ°æ ‡å‡†ç«‹ä½“æ ¡æ­£
                    self.R1, self.R2, self.P1, self.P2, self.Q, _, _ = cv2.stereoRectify(
                        cameraMatrix1=self.K1, distCoeffs1=self.D1,
                        cameraMatrix2=self.K2, distCoeffs2=self.D2,
                        imageSize=(w, h),
                        R=self.R, T=T_meters,
                        flags=cv2.CALIB_ZERO_DISPARITY,
                        alpha=0.0
                    )
                    
                    # ä½¿ç”¨æ ‡å‡†æ ¡æ­£æ˜ å°„
                    self.map1_left, self.map2_left = cv2.initUndistortRectifyMap(
                        self.K1, self.D1, self.R1, self.P1, (w, h), cv2.CV_16SC2
                    )
                    self.map1_right, self.map2_right = cv2.initUndistortRectifyMap(
                        self.K2, self.D2, self.R2, self.P2, (w, h), cv2.CV_16SC2
                    )
                    
                    print("âœ… æ ‡å‡†ç«‹ä½“æ ¡æ­£è®¾ç½®å®Œæˆï¼ˆé±¼çœ¼å‚æ•°ï¼‰")
                
            else:
                # é’ˆå­”ç«‹ä½“æ ¡æ­£
                self.R1, self.R2, self.P1, self.P2, self.Q, _, _ = cv2.stereoRectify(
                    cameraMatrix1=self.K1, distCoeffs1=self.D1,
                    cameraMatrix2=self.K2, distCoeffs2=self.D2,
                    imageSize=(w, h),
                    R=self.R, T=T_meters,
                    flags=cv2.CALIB_ZERO_DISPARITY,
                    alpha=0.0
                )
                
                # è®¡ç®—æ ¡æ­£æ˜ å°„
                self.map1_left, self.map2_left = cv2.initUndistortRectifyMap(
                    self.K1, self.D1, self.R1, self.P1, (w, h), cv2.CV_16SC2
                )
                self.map1_right, self.map2_right = cv2.initUndistortRectifyMap(
                    self.K2, self.D2, self.R2, self.P2, (w, h), cv2.CV_16SC2
                )
                
                print("âœ… é’ˆå­”ç«‹ä½“æ ¡æ­£è®¾ç½®å®Œæˆ")
            
            # è®¾ç½®è§†å·®è®¡ç®—å™¨
            self.setup_stereo_matcher()
            
            # è®¡ç®—åŸºçº¿è·ç¦»
            baseline = abs(T_meters[0, 0])
            print(f"åŸºçº¿è·ç¦»: {baseline:.3f}m")
            print(f"æ ¡æ­£åå·¦ç›¸æœºç„¦è·: fx={self.P1[0,0]:.1f}, fy={self.P1[1,1]:.1f}")
            print(f"æ ¡æ­£åå³ç›¸æœºç„¦è·: fx={self.P2[0,0]:.1f}, fy={self.P2[1,1]:.1f}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç«‹ä½“æ ¡æ­£è®¾ç½®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def setup_stereo_matcher(self, min_disparity=0, num_disparities=128, block_size=5, uniqueness_ratio=10):
        """è®¾ç½®ç«‹ä½“åŒ¹é…å™¨ï¼ˆæ”¯æŒå¤–éƒ¨å‚æ•°ï¼‰"""
        # ç¡®ä¿å‚æ•°æœ‰æ•ˆæ€§
        if num_disparities % 16 != 0:
            num_disparities = (num_disparities // 16) * 16
            print(f"è°ƒæ•´è§†å·®èŒƒå›´ä¸º16çš„å€æ•°: {num_disparities}")
        
        if block_size % 2 == 0:
            block_size += 1
            print(f"è°ƒæ•´å—å¤§å°ä¸ºå¥‡æ•°: {block_size}")
        
        # è®¡ç®—P1å’ŒP2å‚æ•°
        P1 = 8 * 3 * block_size ** 2
        P2 = 32 * 3 * block_size ** 2
        
        self.stereo_matcher = cv2.StereoSGBM_create(
            minDisparity=min_disparity,
            numDisparities=num_disparities,
            blockSize=block_size,
            P1=P1,
            P2=P2,
            disp12MaxDiff=1,  # ä¸¥æ ¼ä¸€è‡´æ€§æ£€æŸ¥
            uniquenessRatio=uniqueness_ratio,  # å¯è°ƒæ•´çš„å”¯ä¸€æ€§è¦æ±‚
            speckleWindowSize=200,  # å¢å¤§æ–‘ç‚¹çª—å£
            speckleRange=32,  # å¢å¤§æ–‘ç‚¹èŒƒå›´
            preFilterCap=63,  # æ¢å¤é¢„æ»¤æ³¢å¼ºåº¦
            mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY
        )
        
        print(f"âœ… ç«‹ä½“åŒ¹é…å™¨è®¾ç½®å®Œæˆ")
        print(f"å‚æ•°: æœ€å°è§†å·®={min_disparity}, è§†å·®èŒƒå›´={num_disparities}, å—å¤§å°={block_size}x{block_size}")
        print(f"      å”¯ä¸€æ€§={uniqueness_ratio}, P1={P1}, P2={P2}")

    def update_sgbm_params(self, min_disparity=0, num_disparities=128, block_size=5, uniqueness_ratio=10):
        """æ›´æ–°SGBMå‚æ•°"""
        self.setup_stereo_matcher(min_disparity, num_disparities, block_size, uniqueness_ratio)
    
    def rectify_stereo_pair(self, left_image: np.ndarray, right_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """æ ¡æ­£ç«‹ä½“å›¾åƒå¯¹"""
        try:
            if self.map1_left is None:
                # é¦–æ¬¡ä½¿ç”¨ï¼Œè®¾ç½®ç«‹ä½“æ ¡æ­£
                h, w = left_image.shape[:2]
                if not self.setup_stereo_rectification((w, h)):
                    raise ValueError("ç«‹ä½“æ ¡æ­£è®¾ç½®å¤±è´¥")
            
            # åº”ç”¨æ ¡æ­£æ˜ å°„
            rectified_left = cv2.remap(left_image, self.map1_left, self.map2_left, cv2.INTER_LINEAR)
            rectified_right = cv2.remap(right_image, self.map1_right, self.map2_right, cv2.INTER_LINEAR)
            
            return rectified_left, rectified_right
            
        except Exception as e:
            print(f"âŒ ç«‹ä½“æ ¡æ­£å¤±è´¥: {e}")
            return left_image, right_image
    
    def compute_disparity(self, left_image: np.ndarray, right_image: np.ndarray) -> np.ndarray:
        """è®¡ç®—è§†å·®å›¾ï¼ˆå¢å¼ºé¢„å¤„ç†å’Œåå¤„ç†ï¼‰"""
        try:
            # æ ¡æ­£å›¾åƒ
            rect_left, rect_right = self.rectify_stereo_pair(left_image, right_image)
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(rect_left.shape) == 3:
                gray_left = cv2.cvtColor(rect_left, cv2.COLOR_BGR2GRAY)
            else:
                gray_left = rect_left
                
            if len(rect_right.shape) == 3:
                gray_right = cv2.cvtColor(rect_right, cv2.COLOR_BGR2GRAY)
            else:
                gray_right = rect_right
            
            # å¢å¼ºé¢„å¤„ç†
            # 1. ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼Œæé«˜å¯¹æ¯”åº¦
            gray_left = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(gray_left)
            gray_right = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(gray_right)
            
            # 2. è½»å¾®é«˜æ–¯æ»¤æ³¢å‡å™ª
            gray_left = cv2.GaussianBlur(gray_left, (3, 3), 0)
            gray_right = cv2.GaussianBlur(gray_right, (3, 3), 0)

# è®¡ç®—è§†å·®
            disparity = self.stereo_matcher.compute(gray_left, gray_right)
            
            # è½¬æ¢ä¸ºæµ®ç‚¹æ•°å¹¶å½’ä¸€åŒ–
            disparity = disparity.astype(np.float32) / 16.0
            
            # å¢å¼ºåå¤„ç†
            # 1. å»é™¤æ˜æ˜¾é”™è¯¯çš„è§†å·®å€¼
            disparity[disparity < 0] = 0
            disparity[disparity > 128] = 0
            
            # 2. å½¢æ€å­¦æ“ä½œå»é™¤å°å™ªå£°
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            disparity_cleaned = cv2.morphologyEx(disparity, cv2.MORPH_CLOSE, kernel)
            
            # 3. åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜åŒæ—¶å¹³æ»‘
            disparity_filtered = cv2.bilateralFilter(
                disparity_cleaned.astype(np.uint8), 9, 75, 75
            ).astype(np.float32)
            
            return disparity_filtered
            
        except Exception as e:
            print(f"âŒ è®¡ç®—è§†å·®å¤±è´¥: {e}")
            return np.zeros((480, 640), dtype=np.float32)
    
    def get_depth_at_point(self, u: int, v: int, disparity_map: np.ndarray) -> Optional[float]:
        """è·å–æŒ‡å®šåƒç´ ç‚¹çš„æ·±åº¦å€¼"""
        try:
            if disparity_map is None or disparity_map.size == 0:
                return None
            
            h, w = disparity_map.shape
            if not (0 <= u < w and 0 <= v < h):
                print(f"âš ï¸ åæ ‡è¶…å‡ºèŒƒå›´: ({u}, {v}), å›¾åƒå°ºå¯¸: {w}x{h}")
                return None
            
            # è·å–è§†å·®å€¼
            disparity = disparity_map[v, u]
            
            # æ£€æŸ¥è§†å·®æœ‰æ•ˆæ€§
            if disparity <= 0:
                print(f"âš ï¸ æ— æ•ˆè§†å·®: {disparity}")
                return None
            
            # è®¡ç®—æ·±åº¦ï¼ˆä½¿ç”¨åŸºçº¿å’Œç„¦è·ï¼‰
            baseline = abs(self.T[0, 0]) / 1000.0  # è½¬æ¢ä¸ºç±³
            focal_length = (self.K1[0, 0] + self.K2[0, 0]) / 2  # å¹³å‡ç„¦è·
            
            depth = (focal_length * baseline) / disparity
            
            print(f"æ·±åº¦è®¡ç®—: è§†å·®={disparity:.2f}, åŸºçº¿={baseline:.3f}m, ç„¦è·={focal_length:.1f}, æ·±åº¦={depth:.3f}m")
            
            return depth
            
        except Exception as e:
            print(f"âŒ æ·±åº¦è®¡ç®—å¤±è´¥: {e}")
            return None
    
    def estimate_depth_region(self, u: int, v: int, disparity_map: np.ndarray, 
                            region_size: int = 9) -> Optional[float]:
        """ä¼°è®¡åŒºåŸŸå¹³å‡æ·±åº¦ï¼ˆæé«˜ç¨³å®šæ€§å’Œç²¾åº¦ï¼‰"""
        try:
            h, w = disparity_map.shape
            
            # è®¡ç®—åŒºåŸŸè¾¹ç•Œ
            half_size = region_size // 2
            u_min = max(0, u - half_size)
            u_max = min(w, u + half_size + 1)
            v_min = max(0, v - half_size)
            v_max = min(h, v + half_size + 1)
            
            # æå–åŒºåŸŸ
            region = disparity_map[v_min:v_max, u_min:u_max]
            
            # è¿‡æ»¤æ— æ•ˆè§†å·®
            valid_disparities = region[region > 0]
            
            if len(valid_disparities) < 3:  # è‡³å°‘éœ€è¦3ä¸ªæœ‰æ•ˆç‚¹
                print(f"âš ï¸ åŒºåŸŸå†…æœ‰æ•ˆè§†å·®ä¸è¶³: {len(valid_disparities)}")
                return None
            
            # ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•æé«˜ç¨³å®šæ€§
            mean_disparity = np.mean(valid_disparities)
            std_disparity = np.std(valid_disparities)
            
            # å»é™¤å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡2ä¸ªæ ‡å‡†å·®çš„ç‚¹ï¼‰
            filtered_disparities = valid_disparities[
                np.abs(valid_disparities - mean_disparity) <= 2 * std_disparity
            ]
            
            if len(filtered_disparities) == 0:
                median_disparity = mean_disparity
            else:
                median_disparity = np.median(filtered_disparities)
            
            # è®¡ç®—æ·±åº¦
            baseline = abs(self.T[0, 0]) / 1000.0  # è½¬æ¢ä¸ºç±³
            focal_length = (self.K1[0, 0] + self.K2[0, 0]) / 2  # å¹³å‡ç„¦è·
            depth = (focal_length * baseline) / median_disparity
            
            print(f"åŒºåŸŸæ·±åº¦ä¼°è®¡: è§†å·®={median_disparity:.2f}Â±{std_disparity:.2f}, æ·±åº¦={depth:.3f}m, æœ‰æ•ˆåƒç´ ={len(valid_disparities)}/{region.size}")
            
            return depth
            
        except Exception as e:
            print(f"âŒ åŒºåŸŸæ·±åº¦ä¼°è®¡å¤±è´¥: {e}")
            return None
    
    def create_depth_map(self, left_image: np.ndarray, right_image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """åˆ›å»ºæ·±åº¦å›¾ï¼ˆå¢å¼ºè´¨é‡ï¼‰"""
        try:
            # è®¡ç®—è§†å·®å›¾
            disparity_map = self.compute_disparity(left_image, right_image)
            
            # åˆ›å»ºæ·±åº¦å›¾
            depth_map = np.zeros_like(disparity_map, dtype=np.float32)
            
            # è·å–æœ‰æ•ˆè§†å·®çš„æ©ç 
            valid_mask = disparity_map > 0
            
            # è®¡ç®—æ·±åº¦
            baseline = abs(self.T[0, 0]) / 1000.0  # è½¬æ¢ä¸ºç±³
            focal_length = (self.K1[0, 0] + self.K2[0, 0]) / 2  # å¹³å‡ç„¦è·
            
            # æ‰¹é‡è®¡ç®—æ·±åº¦
            depth_map[valid_mask] = (focal_length * baseline) / disparity_map[valid_mask]
            
            # æ·±åº¦èŒƒå›´é™åˆ¶å’Œå¹³æ»‘
            depth_map = np.clip(depth_map, 0.05, 1.5)
            
            # å¯¹æ·±åº¦å›¾è¿›è¡Œå¹³æ»‘å¤„ç†
            if np.sum(valid_mask) > 0:
                # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜
                depth_map_smooth = cv2.bilateralFilter(
                    depth_map.astype(np.float32), 5, 50, 50
                )
                # åªåœ¨æœ‰æ•ˆåŒºåŸŸåº”ç”¨å¹³æ»‘
                depth_map[valid_mask] = depth_map_smooth[valid_mask]
            
            return depth_map, disparity_map
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ·±åº¦å›¾å¤±è´¥: {e}")
            return np.zeros((480, 640), dtype=np.float32), np.zeros((480, 640), dtype=np.float32)
    
    def get_3d_point(self, u: int, v: int, left_image: np.ndarray, right_image: np.ndarray) -> Optional[Tuple[float, float, float]]:
        """è·å–æŒ‡å®šåƒç´ ç‚¹çš„3Dåæ ‡ï¼ˆå·¦ç›¸æœºåæ ‡ç³»ï¼‰"""
        try:
            # è®¡ç®—è§†å·®å›¾
            disparity_map = self.compute_disparity(left_image, right_image)
            
            # è·å–æ·±åº¦
            depth = self.estimate_depth_region(u, v, disparity_map, region_size=9)
            
            if depth is None:
                return None
            
            # è®¡ç®—3Dåæ ‡ï¼ˆä½¿ç”¨å·¦ç›¸æœºåŸå§‹å†…å‚ï¼Œä¸æ‰‹çœ¼æ ‡å®šä¸€è‡´ï¼‰
            fx = self.K1[0, 0]
            fy = self.K1[1, 1]
            cx = self.K1[0, 2]
            cy = self.K1[1, 2]
            
            # ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dç‚¹
            X = (u - cx) * depth / fx
            Y = (v - cy) * depth / fy
            Z = depth
            
            print(f"3Dç‚¹è®¡ç®—: åƒç´ ({u}, {v}) â†’ å·¦ç›¸æœºåæ ‡({X:.3f}, {Y:.3f}, {Z:.3f})m")
            
            return (X, Y, Z)
            
        except Exception as e:
            print(f"âŒ 3Dç‚¹è®¡ç®—å¤±è´¥: {e}")
            return None
    
    def visualize_depth(self, depth_map: np.ndarray, disparity_map: np.ndarray) -> np.ndarray:
        """å¯è§†åŒ–æ·±åº¦å›¾ï¼ˆå¢å¼ºæ˜¾ç¤ºæ•ˆæœï¼‰"""
        try:
            # å½’ä¸€åŒ–æ·±åº¦å›¾ç”¨äºæ˜¾ç¤º
            valid_mask = depth_map > 0
            if np.sum(valid_mask) == 0:
                return np.zeros((*depth_map.shape, 3), dtype=np.uint8)
            
            # ä½¿ç”¨æ›´å¥½çš„æ·±åº¦èŒƒå›´
            valid_depths = depth_map[valid_mask]
            # å»é™¤æå€¼ï¼Œä½¿ç”¨95%åˆ†ä½æ•°ä½œä¸ºèŒƒå›´
            min_depth = np.percentile(valid_depths, 5)
            max_depth = np.percentile(valid_depths, 95)
            
            normalized_depth = np.zeros_like(depth_map)
            if max_depth > min_depth:
                # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
                clipped_depth = np.clip(depth_map, min_depth, max_depth)
                normalized_depth[valid_mask] = 255 * (clipped_depth[valid_mask] - min_depth) / (max_depth - min_depth)
            
            # åº”ç”¨æ›´å¥½çš„é¢œè‰²æ˜ å°„
            depth_colored = cv2.applyColorMap(normalized_depth.astype(np.uint8), cv2.COLORMAP_TURBO)
            
            # æ— æ•ˆåŒºåŸŸè®¾ä¸ºé»‘è‰²
            depth_colored[~valid_mask] = [0, 0, 0]
            
            # æ·»åŠ æ·±åº¦ä¿¡æ¯æ–‡æœ¬
            valid_percent = np.sum(valid_mask) / depth_map.size * 100
            cv2.putText(depth_colored, f"Depth: {min_depth:.2f}m - {max_depth:.2f}m", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(depth_colored, f"Valid: {valid_percent:.1f}%, Baseline: {abs(self.T[0,0])/1000:.3f}m", 
                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            return depth_colored
            
        except Exception as e:
            print(f"âŒ æ·±åº¦å¯è§†åŒ–å¤±è´¥: {e}")
            return np.zeros((*depth_map.shape, 3), dtype=np.uint8)

def test_depth_estimation():
    """æµ‹è¯•æ·±åº¦ä¼°è®¡åŠŸèƒ½"""
    print("ğŸ¯ åŒç›®é±¼çœ¼æ·±åº¦ä¼°è®¡æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæ·±åº¦ä¼°è®¡å™¨
    estimator = StereoDepthEstimator()
    
    # æ‰“å¼€åŒç›®ç›¸æœº
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€ç›¸æœº")
        return
    
    # è®¾ç½®åˆ†è¾¨ç‡
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    print("ğŸ“· åŒç›®ç›¸æœºå·²å¯åŠ¨")
    print("ğŸ’¡ æ“ä½œè¯´æ˜:")
    print("  - æŒ‰ 'q' é€€å‡º")
    print("  - æŒ‰ 'd' æ˜¾ç¤º/éšè—æ·±åº¦å›¾")
    print("  - æŒ‰ 'r' æ˜¾ç¤º/éšè—æ ¡æ­£å›¾åƒ")
    print("  - é¼ æ ‡å·¦é”®ç‚¹å‡»è·å–æ·±åº¦å€¼")
    print("  - é¼ æ ‡å³é”®ç‚¹å‡»è·å–3Dåæ ‡")
    
    show_depth = False
    show_rectified = False
    
    def mouse_callback(event, x, y, flags, param):
        """é¼ æ ‡å›è°ƒå‡½æ•°"""
        left_img, right_img = param
        if left_img is None or right_img is None:
            return
            
        if event == cv2.EVENT_LBUTTONDOWN:
            # å·¦é”®ï¼šè·å–æ·±åº¦å€¼
            disparity_map = estimator.compute_disparity(left_img, right_img)
            depth = estimator.estimate_depth_region(x, y, disparity_map)
            if depth:
                print(f"ğŸ¯ ç‚¹å‡»åæ ‡({x}, {y}) â†’ æ·±åº¦: {depth:.3f}m")
            else:
                print(f"âŒ æ— æ³•è·å–ç‚¹å‡»åæ ‡({x}, {y})çš„æ·±åº¦")
                
        elif event == cv2.EVENT_RBUTTONDOWN:
            # å³é”®ï¼šè·å–3Dåæ ‡
            point_3d = estimator.get_3d_point(x, y, left_img, right_img)
            if point_3d:
                X, Y, Z = point_3d
                print(f"ğŸ¯ ç‚¹å‡»åæ ‡({x}, {y}) â†’ 3Dåæ ‡: X={X:.3f}m, Y={Y:.3f}m, Z={Z:.3f}m")
            else:
                print(f"âŒ æ— æ³•è·å–ç‚¹å‡»åæ ‡({x}, {y})çš„3Dåæ ‡")
    
    # è®¾ç½®é¼ æ ‡å›è°ƒ
    cv2.namedWindow('Stereo Depth Estimation', cv2.WINDOW_AUTOSIZE)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # åˆ†ç¦»å·¦å³å›¾åƒ
        left_img = frame[:, 0:640]
        right_img = frame[:, 640:1280]
        
        # è®¾ç½®é¼ æ ‡å›è°ƒå‚æ•°
        cv2.setMouseCallback('Stereo Depth Estimation', mouse_callback, (left_img, right_img))
        
        if show_depth:
            # æ˜¾ç¤ºæ·±åº¦å›¾æ¨¡å¼
            depth_map, disparity_map = estimator.create_depth_map(left_img, right_img)
            depth_vis = estimator.visualize_depth(depth_map, disparity_map)
            
            if show_rectified:
                # æ˜¾ç¤ºæ ¡æ­£åçš„å›¾åƒ
                rect_left, rect_right = estimator.rectify_stereo_pair(left_img, right_img)
                top_row = np.hstack((rect_left, rect_right))
                bottom_row = np.hstack((depth_vis, depth_vis))  # æ·±åº¦å›¾æ˜¾ç¤ºä¸¤æ¬¡
                display = np.vstack((top_row, bottom_row))
                
                # æ·»åŠ æ ‡ç­¾
                cv2.putText(display, "Left Rectified", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(display, "Right Rectified", (650, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(display, "Depth Map", (10, 510), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(display, "Disparity Map", (650, 510), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            else:
                # åªæ˜¾ç¤ºæ·±åº¦å›¾
                display = depth_vis
                cv2.putText(display, "Depth Map (Left Click: Depth, Right Click: 3D)", 
                           (10, display.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        else:
            # æ˜¾ç¤ºåŸå§‹å·¦å³å›¾åƒ
            display = frame
            cv2.putText(display, "Left Camera", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(display, "Right Camera", (650, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(display, "Press 'd' for depth, 'r' for rectified", (10, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        cv2.imshow('Stereo Depth Estimation', display)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('d'):
            show_depth = not show_depth
            print(f"åˆ‡æ¢æ˜¾ç¤ºæ¨¡å¼: {'æ·±åº¦å›¾' if show_depth else 'åŸå§‹å›¾åƒ'}")
        elif key == ord('r'):
            show_rectified = not show_rectified
            print(f"æ ¡æ­£å›¾åƒæ˜¾ç¤º: {'å¼€å¯' if show_rectified else 'å…³é—­'}")
    
    cap.release()
    cv2.destroyAllWindows()
    print("âœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_depth_estimation()
